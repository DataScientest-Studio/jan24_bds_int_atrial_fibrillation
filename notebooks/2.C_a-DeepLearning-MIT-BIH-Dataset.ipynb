{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:30:30.263129Z",
     "iopub.status.busy": "2024-03-20T11:30:30.262200Z",
     "iopub.status.idle": "2024-03-20T11:30:49.092724Z",
     "shell.execute_reply": "2024-03-20T11:30:49.091584Z",
     "shell.execute_reply.started": "2024-03-20T11:30:30.263095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "## Transformation - SMOTE, Downsampling, Scaling\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample \n",
    "\n",
    "## Deep Learning Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Model Performance Evaluation\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print('Libraries imported successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:35:14.869101Z",
     "iopub.status.busy": "2024-03-20T11:35:14.867833Z",
     "iopub.status.idle": "2024-03-20T11:35:16.420374Z",
     "shell.execute_reply": "2024-03-20T11:35:16.419381Z",
     "shell.execute_reply.started": "2024-03-20T11:35:14.869044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading MIT-BIH Arrhythmia Dataset as an example\n",
    "df = pd.read_csv('/kaggle/input/MIT-BIH Arrhythmia Database.csv') \n",
    "\n",
    "unique_types = df['type'].unique()\n",
    "print(unique_types)\n",
    "print(df.shape)\n",
    "\n",
    "# Create binary target variable \n",
    "df['type'].value_counts()\n",
    "class_mapping_lambda = lambda x: 0 if x == 'N' else 1\n",
    "df['label'] = df['type'].apply(class_mapping_lambda)\n",
    "\n",
    "# Print the value counts of the new 'class' column\n",
    "print(df['label'].value_counts())\n",
    "df.drop(['type', 'record'], axis=1, inplace=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Downscaling, train test splot and scaling of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:35:22.072046Z",
     "iopub.status.busy": "2024-03-20T11:35:22.071658Z",
     "iopub.status.idle": "2024-03-20T11:35:22.191187Z",
     "shell.execute_reply": "2024-03-20T11:35:22.189935Z",
     "shell.execute_reply.started": "2024-03-20T11:35:22.072018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(['label'], axis=1)  # Features\n",
    "y = df['label']  # Target variable\n",
    "\n",
    "# Split the dataset into 80% training20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save original training dataset for later reference\n",
    "X_train_original = X_train\n",
    "y_train_original = y_train\n",
    "\n",
    "# Scaling of features \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:35:51.512280Z",
     "iopub.status.busy": "2024-03-20T11:35:51.511900Z",
     "iopub.status.idle": "2024-03-20T11:35:51.581536Z",
     "shell.execute_reply": "2024-03-20T11:35:51.579920Z",
     "shell.execute_reply.started": "2024-03-20T11:35:51.512252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate majority and minority classes in original data\n",
    "majority_class = df[df['label'] == 0]\n",
    "minority_class = df[df['label'] == 1]\n",
    "\n",
    "# Downsample the majority class\n",
    "downsampled_majority = resample(majority_class, \n",
    "                                replace=False,    # Sample without replacement\n",
    "                                n_samples=len(minority_class),  # Match minority class size\n",
    "                                random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "balanced_df = pd.concat([downsampled_majority, minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Check the class distribution\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "# Further downsample the balanced dataset\n",
    "downsampled_balanced = resample(balanced_df, \n",
    "                         replace=False,    # Sample without replacement\n",
    "                                n_samples=10000,  # Set desired size\n",
    "                                random_state=42)  # Reproducible results\n",
    "\n",
    "# Shuffle the downsampled dataset\n",
    "downsampled_balanced = downsampled_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "# Check the class distribution\n",
    "print(downsampled_balanced['label'].value_counts())\n",
    "\n",
    "# Splitting the dataset into features (X) and labels (y)\n",
    "X_train_ds = downsampled_balanced.drop(columns=['label'])\n",
    "y_train_ds = downsampled_balanced['label']\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Shape of X_train after downsampling:\", X_train_ds.shape)\n",
    "print(\"Shape of y_train after downsampling:\", y_train_ds.shape)\n",
    "\n",
    "X_train = X_train_ds\n",
    "y_train = y_train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Networks - Comparison of different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T17:23:34.651076Z",
     "iopub.status.busy": "2024-03-15T17:23:34.650577Z",
     "iopub.status.idle": "2024-03-15T18:17:29.102132Z",
     "shell.execute_reply": "2024-03-15T18:17:29.100566Z",
     "shell.execute_reply.started": "2024-03-15T17:23:34.651039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the list of activation functions to compare\n",
    "activation_functions = [\"relu\", \"sigmoid\", \"tanh\",]\n",
    "\n",
    "# Create a dictionary to store classification reports and confusion matrices\n",
    "results_dnn = {}\n",
    "\n",
    "# Iterate over each activation function\n",
    "for activation_func in activation_functions:\n",
    "    # Build the DNN model\n",
    "    inputs = Input(shape=(32,), name=\"Input\")\n",
    "    dense1 = Dense(units=10, activation=activation_func, name=\"Dense_1\")\n",
    "    dense2 = Dense(units=8, activation=activation_func, name=\"Dense_2\")\n",
    "    dense3 = Dense(units=6, activation=activation_func, name=\"Dense_3\")\n",
    "    dense4 = Dense(units=2, activation=\"softmax\", name=\"Dense_4\")  # 2 output units for binary classification\n",
    "    x = dense1(inputs)\n",
    "    x = dense2(x)\n",
    "    x = dense3(x)\n",
    "    outputs = dense4(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model_dnn = Model(inputs=inputs, outputs=outputs)\n",
    "    model_dnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    history = model_dnn.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=0)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model_dnn.predict(X_test)\n",
    "    y_pred_class_dnn = np.argmax(y_pred, axis=1) \n",
    "\n",
    "    # Evaluate model performance\n",
    "    report = classification_report(y_test, y_pred_class_dnn, output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_class_dnn)\n",
    "\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    results_dnn[activation_func] = {}\n",
    "    results_dnn[activation_func]['classification_report'] = report\n",
    "    results_dnn[activation_func]['confusion_matrix'] = confusion_mat\n",
    "    results_dnn[activation_func]['y_pred_class_dnn'] = y_pred_class_dnn\n",
    "    \n",
    "# Print and analyze the results\n",
    "for activation_func, result in results_dnn.items():\n",
    "    print(f\"Activation Function: {activation_func}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(result['classification_report']))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['confusion_matrix'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matirces DNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T18:47:14.741848Z",
     "iopub.status.busy": "2024-03-15T18:47:14.740644Z",
     "iopub.status.idle": "2024-03-15T18:47:15.212589Z",
     "shell.execute_reply": "2024-03-15T18:47:15.211319Z",
     "shell.execute_reply.started": "2024-03-15T18:47:14.741788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "num_activation_functions = len(results_dnn)\n",
    "num_cols = 3\n",
    "num_rows = (num_activation_functions + num_cols - 1) // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 5 * num_rows))\n",
    "\n",
    "for idx, (activation_func, result) in enumerate(results_dnn.items()):\n",
    "    plt.subplot(num_rows, num_cols, idx+1)\n",
    "    sns.heatmap(result['confusion_matrix'], annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "    plt.title(f'{activation_func}', fontsize=14)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network - Comparison of different activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T18:47:56.547293Z",
     "iopub.status.busy": "2024-03-15T18:47:56.546847Z",
     "iopub.status.idle": "2024-03-15T19:41:19.327539Z",
     "shell.execute_reply": "2024-03-15T19:41:19.325801Z",
     "shell.execute_reply.started": "2024-03-15T18:47:56.547258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define activation functions to compare\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results_ann = {}\n",
    "\n",
    "# Loop through activation functions and train models\n",
    "for activation_func in activation_functions:\n",
    "    # Create and train ANN model\n",
    "    model_ann = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=4, activation=activation_func, input_shape=(32,)),\n",
    "        tf.keras.layers.Dense(units=4, activation=activation_func),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Recall'])\n",
    "    model_ann.fit(X_train, y_train, batch_size=10, epochs=500, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_ann = model_ann.predict(X_test)\n",
    "    y_pred_class_ann = (y_pred_ann > 0.5).astype(\"int32\")\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    report = classification_report(y_test, y_pred_class_ann, output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_class_ann)\n",
    "    \n",
    "    # Store results in the dictionary\n",
    "    results_ann[activation_func] = {}\n",
    "    results_ann[activation_func]['classification_report'] = report\n",
    "    results_ann[activation_func]['confusion_matrix'] = confusion_mat\n",
    "    results_ann[activation_func]['y_pred_class_ann'] = y_pred_class_ann\n",
    "\n",
    "# Print the results\n",
    "for activation_func, result in results_ann.items():\n",
    "    print(f\"Activation Function: {activation_func}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(result['classification_report']))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['confusion_matrix'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T19:41:43.949110Z",
     "iopub.status.busy": "2024-03-15T19:41:43.948529Z",
     "iopub.status.idle": "2024-03-15T19:41:44.461864Z",
     "shell.execute_reply": "2024-03-15T19:41:44.460595Z",
     "shell.execute_reply.started": "2024-03-15T19:41:43.949069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "num_activation_functions = len(results_ann)\n",
    "num_cols = 3\n",
    "num_rows = (num_activation_functions + num_cols - 1) // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 5 * num_rows))\n",
    "\n",
    "for idx, (activation_func, result) in enumerate(results_ann.items()):\n",
    "    plt.subplot(num_rows, num_cols, idx+1)\n",
    "    sns.heatmap(result['confusion_matrix'], annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "    plt.title(f'{activation_func}', fontsize=14)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T20:02:44.840875Z",
     "iopub.status.busy": "2024-03-15T20:02:44.840309Z",
     "iopub.status.idle": "2024-03-15T20:02:45.300480Z",
     "shell.execute_reply": "2024-03-15T20:02:45.299281Z",
     "shell.execute_reply.started": "2024-03-15T20:02:44.840816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define activation functions for DNN\n",
    "activation_functions_dnn = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot ROC curves for DNN\n",
    "plt.figure(figsize=(10, 8))\n",
    "for activation_func, result in results_dnn.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result[\"y_pred_class_dnn\"])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'DNN {activation_func} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Define activation functions for ANN\n",
    "activation_functions_ann = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot ROC curves for ANN\n",
    "for activation_func, result in results_ann.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result[\"y_pred_class_ann\"])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'ANN {activation_func} (AUC = {roc_auc:.2f})', linestyle='dashed')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curves for DNN and ANN', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T20:02:12.415191Z",
     "iopub.status.busy": "2024-03-15T20:02:12.414725Z",
     "iopub.status.idle": "2024-03-15T20:02:12.887224Z",
     "shell.execute_reply": "2024-03-15T20:02:12.885656Z",
     "shell.execute_reply.started": "2024-03-15T20:02:12.415159Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Define activation functions for DNN\n",
    "activation_functions_dnn = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot precision-recall curves for DNN\n",
    "plt.figure(figsize=(10, 8))\n",
    "for activation_func, result in results_dnn.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_test, result[\"y_pred_class_dnn\"])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'DNN {activation_func} (AUC = {pr_auc:.2f})')\n",
    "\n",
    "# Define activation functions for ANN\n",
    "activation_functions_ann = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot precision-recall curves for ANN\n",
    "for activation_func, result in results_ann.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_test, result[\"y_pred_class_ann\"])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'ANN {activation_func} (AUC = {pr_auc:.2f})', linestyle='dashed')\n",
    "\n",
    "plt.xlabel('Recall (True Positive Rate)', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curves for DNN and ANN', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model refinement for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:53:19.505054Z",
     "iopub.status.busy": "2024-03-20T12:53:19.504020Z",
     "iopub.status.idle": "2024-03-20T12:57:27.052481Z",
     "shell.execute_reply": "2024-03-20T12:57:27.051212Z",
     "shell.execute_reply.started": "2024-03-20T12:53:19.505017Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL 1 - Define the DNN architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(32,)))  # Input layer with ReLU activation\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dropout(0.2))  # Dropout regularization to reduce overfitting\n",
    "model.add(Dense(16, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_class))\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "y_pred_class_DNN2 = y_pred_class\n",
    "y_pred_class_DNN2 = y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T13:00:13.133921Z",
     "iopub.status.busy": "2024-03-20T13:00:13.133528Z",
     "iopub.status.idle": "2024-03-20T13:04:31.467201Z",
     "shell.execute_reply": "2024-03-20T13:04:31.466185Z",
     "shell.execute_reply.started": "2024-03-20T13:00:13.133894Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL 2 -  Define the DNN architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(32,)))  # Input layer with ReLU activation\n",
    "model.add(Dense(64, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dropout(0.3))  # Dropout regularization to reduce overfitting\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dense(16, activation='relu'))  # Additional hidden layer with ReLU activation\n",
    "model.add(Dense(8, activation='relu'))  # Additional hidden layer with ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_class))\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "y_pred_class_DNN4 = y_pred_class\n",
    "y_pred_class_DNN4 = y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:50:40.977962Z",
     "iopub.status.busy": "2024-03-20T12:50:40.977515Z",
     "iopub.status.idle": "2024-03-20T12:50:41.652275Z",
     "shell.execute_reply": "2024-03-20T12:50:41.651267Z",
     "shell.execute_reply.started": "2024-03-20T12:50:40.977928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define confusion matrices\n",
    "conf_matrix_1 = np.array([[8639, 403], [26, 1001]]) # DNN Model 1 with downsampled 10 k dataset \n",
    "\n",
    "conf_matrix_2 = np.array([[8610, 432], [39, 988]]) # DNN Model 2 with downsampled 10 k dataset \n",
    "\n",
    "# Plot both confusion matrices side by side\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot confusion matrix 1\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(conf_matrix_1, annot=True, cmap=\"Blues\", fmt=\"d\", annot_kws={\"fontsize\": 14})\n",
    "plt.title(\"DNN Model 1 - downsampled dataset 10k\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "plt.ylabel(\"True Labels\", fontsize=14)\n",
    "\n",
    "# Plot confusion matrix 2\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(conf_matrix_2, annot=True, cmap=\"Blues\", fmt=\"d\", annot_kws={\"fontsize\": 14})\n",
    "plt.title(\"DNN Model 2 - downsampled dataset 10k\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "plt.ylabel(\"True Labels\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1542181,
     "sourceId": 2543148,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
