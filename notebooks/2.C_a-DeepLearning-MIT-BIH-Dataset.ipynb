{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:30:30.263129Z",
     "iopub.status.busy": "2024-03-20T11:30:30.262200Z",
     "iopub.status.idle": "2024-03-20T11:30:49.092724Z",
     "shell.execute_reply": "2024-03-20T11:30:49.091584Z",
     "shell.execute_reply.started": "2024-03-20T11:30:30.263095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 10:30:17.691044: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 10:30:18.881329: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 10:30:18.885226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 10:30:23.235192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Transformation - SMOTE, Downsampling, Scaling\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample \n",
    "\n",
    "## Deep Learning Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Model Performance Evaluation\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print('Libraries imported successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:35:14.869101Z",
     "iopub.status.busy": "2024-03-20T11:35:14.867833Z",
     "iopub.status.idle": "2024-03-20T11:35:16.420374Z",
     "shell.execute_reply": "2024-03-20T11:35:16.419381Z",
     "shell.execute_reply.started": "2024-03-20T11:35:14.869044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Q' 'SVEB' 'VEB' 'F']\n",
      "(100689, 34)\n",
      "label\n",
      "0    90083\n",
      "1    10606\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_pre-RR</th>\n",
       "      <th>0_post-RR</th>\n",
       "      <th>0_pPeak</th>\n",
       "      <th>0_tPeak</th>\n",
       "      <th>0_rPeak</th>\n",
       "      <th>0_sPeak</th>\n",
       "      <th>0_qPeak</th>\n",
       "      <th>0_qrs_interval</th>\n",
       "      <th>0_pq_interval</th>\n",
       "      <th>0_qt_interval</th>\n",
       "      <th>...</th>\n",
       "      <th>1_qrs_interval</th>\n",
       "      <th>1_pq_interval</th>\n",
       "      <th>1_qt_interval</th>\n",
       "      <th>1_st_interval</th>\n",
       "      <th>1_qrs_morph0</th>\n",
       "      <th>1_qrs_morph1</th>\n",
       "      <th>1_qrs_morph2</th>\n",
       "      <th>1_qrs_morph3</th>\n",
       "      <th>1_qrs_morph4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0.074347</td>\n",
       "      <td>-0.160548</td>\n",
       "      <td>1.036401</td>\n",
       "      <td>-0.285662</td>\n",
       "      <td>-0.026824</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>315.0</td>\n",
       "      <td>-0.052079</td>\n",
       "      <td>-0.264784</td>\n",
       "      <td>0.886597</td>\n",
       "      <td>-0.366298</td>\n",
       "      <td>-0.059710</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.042009</td>\n",
       "      <td>-0.029498</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>315</td>\n",
       "      <td>321.0</td>\n",
       "      <td>-0.062151</td>\n",
       "      <td>-0.296983</td>\n",
       "      <td>0.991859</td>\n",
       "      <td>-0.410306</td>\n",
       "      <td>-0.065686</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321</td>\n",
       "      <td>336.0</td>\n",
       "      <td>-0.063322</td>\n",
       "      <td>-0.281386</td>\n",
       "      <td>1.034903</td>\n",
       "      <td>-0.403880</td>\n",
       "      <td>-0.071750</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020536</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.018965</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336</td>\n",
       "      <td>344.0</td>\n",
       "      <td>-0.062915</td>\n",
       "      <td>1.046914</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>-0.074639</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-0.007798</td>\n",
       "      <td>-0.051155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>344</td>\n",
       "      <td>324.0</td>\n",
       "      <td>-0.083040</td>\n",
       "      <td>-0.293023</td>\n",
       "      <td>0.931546</td>\n",
       "      <td>-0.433485</td>\n",
       "      <td>-0.088745</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.036339</td>\n",
       "      <td>-0.034673</td>\n",
       "      <td>-0.026985</td>\n",
       "      <td>-0.022147</td>\n",
       "      <td>-0.013531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>324</td>\n",
       "      <td>313.0</td>\n",
       "      <td>-0.067520</td>\n",
       "      <td>-0.286934</td>\n",
       "      <td>1.050545</td>\n",
       "      <td>-0.482886</td>\n",
       "      <td>-0.074666</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.032788</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.035176</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>313</td>\n",
       "      <td>313.0</td>\n",
       "      <td>-0.085844</td>\n",
       "      <td>-0.341904</td>\n",
       "      <td>1.154904</td>\n",
       "      <td>-0.439149</td>\n",
       "      <td>-0.094663</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.008229</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>-0.034285</td>\n",
       "      <td>-0.054572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>313</td>\n",
       "      <td>310.0</td>\n",
       "      <td>-0.061510</td>\n",
       "      <td>-0.257011</td>\n",
       "      <td>1.107787</td>\n",
       "      <td>-0.385508</td>\n",
       "      <td>-0.065044</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>-0.020603</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>310</td>\n",
       "      <td>329.0</td>\n",
       "      <td>-0.063513</td>\n",
       "      <td>-0.319736</td>\n",
       "      <td>1.087343</td>\n",
       "      <td>-0.425738</td>\n",
       "      <td>-0.074461</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.060157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_pre-RR  0_post-RR   0_pPeak   0_tPeak   0_rPeak   0_sPeak   0_qPeak  \\\n",
       "0        76      313.0  0.074347 -0.160548  1.036401 -0.285662 -0.026824   \n",
       "1       313      315.0 -0.052079 -0.264784  0.886597 -0.366298 -0.059710   \n",
       "2       315      321.0 -0.062151 -0.296983  0.991859 -0.410306 -0.065686   \n",
       "3       321      336.0 -0.063322 -0.281386  1.034903 -0.403880 -0.071750   \n",
       "4       336      344.0 -0.062915  1.046914  1.046408  1.046408 -0.074639   \n",
       "5       344      324.0 -0.083040 -0.293023  0.931546 -0.433485 -0.088745   \n",
       "6       324      313.0 -0.067520 -0.286934  1.050545 -0.482886 -0.074666   \n",
       "7       313      313.0 -0.085844 -0.341904  1.154904 -0.439149 -0.094663   \n",
       "8       313      310.0 -0.061510 -0.257011  1.107787 -0.385508 -0.065044   \n",
       "9       310      329.0 -0.063513 -0.319736  1.087343 -0.425738 -0.074461   \n",
       "\n",
       "   0_qrs_interval  0_pq_interval  0_qt_interval  ...  1_qrs_interval  \\\n",
       "0              41             18             66  ...               2   \n",
       "1              21              4             33  ...              26   \n",
       "2              22              3             32  ...               3   \n",
       "3              22              4             33  ...               6   \n",
       "4              11              4             16  ...              16   \n",
       "5              22              3             33  ...               8   \n",
       "6              23              3             34  ...              27   \n",
       "7              22              3             31  ...               8   \n",
       "8              25              5             37  ...              21   \n",
       "9              22              4             32  ...              15   \n",
       "\n",
       "   1_pq_interval  1_qt_interval  1_st_interval  1_qrs_morph0  1_qrs_morph1  \\\n",
       "0             18             22              2      0.025930      0.025930   \n",
       "1             27             62              9     -0.042009     -0.029498   \n",
       "2              8             12              1      0.009528      0.009528   \n",
       "3              9             16              1     -0.020536     -0.020257   \n",
       "4              5             31             10      0.016053      0.006742   \n",
       "5             10             19              1     -0.036339     -0.034673   \n",
       "6             10             45              8     -0.032788     -0.017467   \n",
       "7              2             21             11     -0.008229     -0.011703   \n",
       "8             31             61              9     -0.029834     -0.020603   \n",
       "9              2             26              9      0.018915      0.010747   \n",
       "\n",
       "   1_qrs_morph2  1_qrs_morph3  1_qrs_morph4  label  \n",
       "0      0.025930      0.025436      0.025436      0  \n",
       "1      0.005012      0.030892      0.002986      0  \n",
       "2      0.008786      0.008786      0.008368      0  \n",
       "3     -0.018965     -0.016968     -0.014555      0  \n",
       "4      0.002782     -0.007798     -0.051155      0  \n",
       "5     -0.026985     -0.022147     -0.013531      0  \n",
       "6      0.013925      0.035176      0.016576      0  \n",
       "7     -0.024895     -0.034285     -0.054572      0  \n",
       "8      0.004411      0.025997      0.015942      0  \n",
       "9      0.000927     -0.018538     -0.060157      0  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading MIT-BIH Arrhythmia Dataset as an example\n",
    "df = pd.read_csv('MIT-BIH Arrhythmia Database.csv') \n",
    "\n",
    "unique_types = df['type'].unique()\n",
    "print(unique_types)\n",
    "print(df.shape)\n",
    "\n",
    "# Create binary target variable \n",
    "df['type'].value_counts()\n",
    "class_mapping_lambda = lambda x: 0 if x == 'N' else 1\n",
    "df['label'] = df['type'].apply(class_mapping_lambda)\n",
    "\n",
    "# Print the value counts of the new 'class' column\n",
    "print(df['label'].value_counts())\n",
    "df.drop(['type', 'record'], axis=1, inplace=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Downscaling, train test splot and scaling of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:35:22.072046Z",
     "iopub.status.busy": "2024-03-20T11:35:22.071658Z",
     "iopub.status.idle": "2024-03-20T11:35:22.191187Z",
     "shell.execute_reply": "2024-03-20T11:35:22.189935Z",
     "shell.execute_reply.started": "2024-03-20T11:35:22.072018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00047551 0.00047438 0.14460252 0.163272   0.15645161 0.13086489\n",
      " 0.14384207 0.00588235 0.00671141 0.00303951 0.00714286 0.14384207\n",
      " 0.18186031 0.16202895 0.16077164 0.17486125 0.00047551 0.00047438\n",
      " 0.13755979 0.10530541 0.12858414 0.10556911 0.11260797 0.00384615\n",
      " 0.00543478 0.002457   0.0046729  0.11260797 0.12377001 0.1410501\n",
      " 0.15095282 0.13532692]\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(['label'], axis=1)  # Features\n",
    "y = df['label']  # Target variable\n",
    "\n",
    "# Split the dataset into 80% training20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save original training dataset for later reference\n",
    "X_train_original = X_train\n",
    "y_train_original = y_train\n",
    "\n",
    "# Scaling of features \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:35:51.512280Z",
     "iopub.status.busy": "2024-03-20T11:35:51.511900Z",
     "iopub.status.idle": "2024-03-20T11:35:51.581536Z",
     "shell.execute_reply": "2024-03-20T11:35:51.579920Z",
     "shell.execute_reply.started": "2024-03-20T11:35:51.512252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    10606\n",
      "0    10606\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    5047\n",
      "1    4953\n",
      "Name: count, dtype: int64\n",
      "Shape of X_train after downsampling: (10000, 32)\n",
      "Shape of y_train after downsampling: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes in original data\n",
    "majority_class = df[df['label'] == 0]\n",
    "minority_class = df[df['label'] == 1]\n",
    "\n",
    "# Downsample the majority class\n",
    "downsampled_majority = resample(majority_class, \n",
    "                                replace=False,    # Sample without replacement\n",
    "                                n_samples=len(minority_class),  # Match minority class size\n",
    "                                random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "balanced_df = pd.concat([downsampled_majority, minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Check the class distribution\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "# Further downsample the balanced dataset\n",
    "downsampled_balanced = resample(balanced_df, \n",
    "                         replace=False,    # Sample without replacement\n",
    "                                n_samples=10000,  # Set desired size\n",
    "                                random_state=42)  # Reproducible results\n",
    "\n",
    "# Shuffle the downsampled dataset\n",
    "downsampled_balanced = downsampled_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "# Check the class distribution\n",
    "print(downsampled_balanced['label'].value_counts())\n",
    "\n",
    "# Splitting the dataset into features (X) and labels (y)\n",
    "X_train_ds = downsampled_balanced.drop(columns=['label'])\n",
    "y_train_ds = downsampled_balanced['label']\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Shape of X_train after downsampling:\", X_train_ds.shape)\n",
    "print(\"Shape of y_train after downsampling:\", y_train_ds.shape)\n",
    "\n",
    "X_train = X_train_ds\n",
    "y_train = y_train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 1s 2ms/step\n",
      "DNN model with relu activation function results saved to ../models/mit_best_model_DNN_relu.joblib\n",
      "630/630 [==============================] - 1s 2ms/step\n",
      "DNN model with sigmoid activation function results saved to ../models/mit_best_model_DNN_sigmoid.joblib\n",
      "630/630 [==============================] - 1s 2ms/step\n",
      "DNN model with tanh activation function results saved to ../models/mit_best_model_DNN_tanh.joblib\n",
      "630/630 [==============================] - 1s 1ms/step\n",
      "ANN model with relu activation function results saved to ../models/mit_best_model_ANN_relu.joblib\n",
      "630/630 [==============================] - 1s 2ms/step\n",
      "ANN model with sigmoid activation function results saved to ../models/mit_best_model_ANN_sigmoid.joblib\n",
      "630/630 [==============================] - 1s 2ms/step\n",
      "ANN model with tanh activation function results saved to ../models/mit_best_model_ANN_tanh.joblib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the list of activation functions for DNN\n",
    "activation_functions_dnn = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Initialize dictionary to store DNN results\n",
    "results_dnn = {}\n",
    "\n",
    "# Iterate over each activation function for DNN\n",
    "for activation_func in activation_functions_dnn:\n",
    "    # Build the DNN model\n",
    "    inputs = Input(shape=(32,), name=\"Input\")\n",
    "    dense1 = Dense(units=10, activation=activation_func, name=\"Dense_1\")\n",
    "    dense2 = Dense(units=8, activation=activation_func, name=\"Dense_2\")\n",
    "    dense3 = Dense(units=6, activation=activation_func, name=\"Dense_3\")\n",
    "    dense4 = Dense(units=2, activation=\"softmax\", name=\"Dense_4\")  # 2 output units for binary classification\n",
    "    x = dense1(inputs)\n",
    "    x = dense2(x)\n",
    "    x = dense3(x)\n",
    "    outputs = dense4(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model_dnn = Model(inputs=inputs, outputs=outputs)\n",
    "    model_dnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    history = model_dnn.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=0)\n",
    "\n",
    "    # After training, predict and evaluate the model\n",
    "    y_pred_prob_dnn = model_dnn.predict(X_test)\n",
    "    y_pred_class_dnn = np.argmax(y_pred_prob_dnn, axis=1)\n",
    "    report = classification_report(y_test, y_pred_class_dnn, output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_class_dnn)\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    results_dnn[activation_func] = {}\n",
    "    results_dnn[activation_func]['classification_report'] = report\n",
    "    results_dnn[activation_func]['confusion_matrix'] = confusion_mat\n",
    "    results_dnn[activation_func]['y_pred_class_dnn'] = y_pred_class_dnn\n",
    "\n",
    "    # Save the trained model\n",
    "    classifier_name = f\"DNN_{activation_func}\"\n",
    "    model_filename = f'../models/mit_best_model_{classifier_name}.joblib'  # Save in the models directory\n",
    "    joblib.dump(model_dnn, model_filename)\n",
    "\n",
    "    # Optionally, you can also store other metrics or results you're interested in\n",
    "\n",
    "    # Print or log the results\n",
    "    print(f\"DNN model with {activation_func} activation function results saved to {model_filename}\")\n",
    "\n",
    "# Now, do the same for the ANN models\n",
    "# Define activation functions for ANN\n",
    "activation_functions_ann = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "# Initialize dictionary to store ANN results\n",
    "results_ann = {}\n",
    "\n",
    "# Loop through activation functions and train ANN models\n",
    "for activation_func in activation_functions_ann:\n",
    "    # Create and train ANN model\n",
    "    model_ann = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=4, activation=activation_func, input_shape=(32,)),\n",
    "        tf.keras.layers.Dense(units=4, activation=activation_func),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Recall'])\n",
    "    model_ann.fit(X_train, y_train, batch_size=10, epochs=500, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    # After training, predict and evaluate the model\n",
    "    y_pred_class_ann = (model_ann.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred_class_ann, output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_class_ann)\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    results_ann[activation_func] = {}\n",
    "    results_ann[activation_func]['classification_report'] = report\n",
    "    results_ann[activation_func]['confusion_matrix'] = confusion_mat\n",
    "    results_ann[activation_func]['y_pred_class_ann'] = y_pred_class_ann\n",
    "\n",
    "    # Save the trained model\n",
    "    classifier_name = f\"ANN_{activation_func}\"\n",
    "    model_filename = f'../models/mit_best_model_{classifier_name}.joblib'  # Save in the models directory\n",
    "    joblib.dump(model_ann, model_filename)\n",
    "\n",
    "    # Optionally, you can also store other metrics or results you're interested in\n",
    "\n",
    "    # Print or log the results\n",
    "    print(f\"ANN model with {activation_func} activation function results saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Networks - Comparison of different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T17:23:34.651076Z",
     "iopub.status.busy": "2024-03-15T17:23:34.650577Z",
     "iopub.status.idle": "2024-03-15T18:17:29.102132Z",
     "shell.execute_reply": "2024-03-15T18:17:29.100566Z",
     "shell.execute_reply.started": "2024-03-15T17:23:34.651039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the list of activation functions to compare\n",
    "activation_functions = [\"relu\", \"sigmoid\", \"tanh\",]\n",
    "\n",
    "# Create a dictionary to store classification reports and confusion matrices\n",
    "results_dnn = {}\n",
    "\n",
    "# Iterate over each activation function\n",
    "for activation_func in activation_functions:\n",
    "    # Build the DNN model\n",
    "    inputs = Input(shape=(32,), name=\"Input\")\n",
    "    dense1 = Dense(units=10, activation=activation_func, name=\"Dense_1\")\n",
    "    dense2 = Dense(units=8, activation=activation_func, name=\"Dense_2\")\n",
    "    dense3 = Dense(units=6, activation=activation_func, name=\"Dense_3\")\n",
    "    dense4 = Dense(units=2, activation=\"softmax\", name=\"Dense_4\")  # 2 output units for binary classification\n",
    "    x = dense1(inputs)\n",
    "    x = dense2(x)\n",
    "    x = dense3(x)\n",
    "    outputs = dense4(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model_dnn = Model(inputs=inputs, outputs=outputs)\n",
    "    model_dnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    history = model_dnn.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=0)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model_dnn.predict(X_test)\n",
    "    y_pred_class_dnn = np.argmax(y_pred, axis=1) \n",
    "\n",
    "    # Evaluate model performance\n",
    "    report = classification_report(y_test, y_pred_class_dnn, output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_class_dnn)\n",
    "\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    results_dnn[activation_func] = {}\n",
    "    results_dnn[activation_func]['classification_report'] = report\n",
    "    results_dnn[activation_func]['confusion_matrix'] = confusion_mat\n",
    "    results_dnn[activation_func]['y_pred_class_dnn'] = y_pred_class_dnn\n",
    "    \n",
    "# Print and analyze the results\n",
    "for activation_func, result in results_dnn.items():\n",
    "    print(f\"Activation Function: {activation_func}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(result['classification_report']))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['confusion_matrix'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matirces DNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T18:47:14.741848Z",
     "iopub.status.busy": "2024-03-15T18:47:14.740644Z",
     "iopub.status.idle": "2024-03-15T18:47:15.212589Z",
     "shell.execute_reply": "2024-03-15T18:47:15.211319Z",
     "shell.execute_reply.started": "2024-03-15T18:47:14.741788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "num_activation_functions = len(results_dnn)\n",
    "num_cols = 3\n",
    "num_rows = (num_activation_functions + num_cols - 1) // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 5 * num_rows))\n",
    "\n",
    "for idx, (activation_func, result) in enumerate(results_dnn.items()):\n",
    "    plt.subplot(num_rows, num_cols, idx+1)\n",
    "    sns.heatmap(result['confusion_matrix'], annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "    plt.title(f'{activation_func}', fontsize=14)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network - Comparison of different activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T18:47:56.547293Z",
     "iopub.status.busy": "2024-03-15T18:47:56.546847Z",
     "iopub.status.idle": "2024-03-15T19:41:19.327539Z",
     "shell.execute_reply": "2024-03-15T19:41:19.325801Z",
     "shell.execute_reply.started": "2024-03-15T18:47:56.547258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define activation functions to compare\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results_ann = {}\n",
    "\n",
    "# Loop through activation functions and train models\n",
    "for activation_func in activation_functions:\n",
    "    # Create and train ANN model\n",
    "    model_ann = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=4, activation=activation_func, input_shape=(32,)),\n",
    "        tf.keras.layers.Dense(units=4, activation=activation_func),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Recall'])\n",
    "    model_ann.fit(X_train, y_train, batch_size=10, epochs=500, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_ann = model_ann.predict(X_test)\n",
    "    y_pred_class_ann = (y_pred_ann > 0.5).astype(\"int32\")\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    report = classification_report(y_test, y_pred_class_ann, output_dict=True)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_class_ann)\n",
    "    \n",
    "    # Store results in the dictionary\n",
    "    results_ann[activation_func] = {}\n",
    "    results_ann[activation_func]['classification_report'] = report\n",
    "    results_ann[activation_func]['confusion_matrix'] = confusion_mat\n",
    "    results_ann[activation_func]['y_pred_class_ann'] = y_pred_class_ann\n",
    "\n",
    "# Print the results\n",
    "for activation_func, result in results_ann.items():\n",
    "    print(f\"Activation Function: {activation_func}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(result['classification_report']))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['confusion_matrix'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T19:41:43.949110Z",
     "iopub.status.busy": "2024-03-15T19:41:43.948529Z",
     "iopub.status.idle": "2024-03-15T19:41:44.461864Z",
     "shell.execute_reply": "2024-03-15T19:41:44.460595Z",
     "shell.execute_reply.started": "2024-03-15T19:41:43.949069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "num_activation_functions = len(results_ann)\n",
    "num_cols = 3\n",
    "num_rows = (num_activation_functions + num_cols - 1) // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 5 * num_rows))\n",
    "\n",
    "for idx, (activation_func, result) in enumerate(results_ann.items()):\n",
    "    plt.subplot(num_rows, num_cols, idx+1)\n",
    "    sns.heatmap(result['confusion_matrix'], annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "    plt.title(f'{activation_func}', fontsize=14)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T20:02:44.840875Z",
     "iopub.status.busy": "2024-03-15T20:02:44.840309Z",
     "iopub.status.idle": "2024-03-15T20:02:45.300480Z",
     "shell.execute_reply": "2024-03-15T20:02:45.299281Z",
     "shell.execute_reply.started": "2024-03-15T20:02:44.840816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define activation functions for DNN\n",
    "activation_functions_dnn = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot ROC curves for DNN\n",
    "plt.figure(figsize=(10, 8))\n",
    "for activation_func, result in results_dnn.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result[\"y_pred_class_dnn\"])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'DNN {activation_func} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Define activation functions for ANN\n",
    "activation_functions_ann = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot ROC curves for ANN\n",
    "for activation_func, result in results_ann.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result[\"y_pred_class_ann\"])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'ANN {activation_func} (AUC = {roc_auc:.2f})', linestyle='dashed')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curves for DNN and ANN', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T20:02:12.415191Z",
     "iopub.status.busy": "2024-03-15T20:02:12.414725Z",
     "iopub.status.idle": "2024-03-15T20:02:12.887224Z",
     "shell.execute_reply": "2024-03-15T20:02:12.885656Z",
     "shell.execute_reply.started": "2024-03-15T20:02:12.415159Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Define activation functions for DNN\n",
    "activation_functions_dnn = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot precision-recall curves for DNN\n",
    "plt.figure(figsize=(10, 8))\n",
    "for activation_func, result in results_dnn.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_test, result[\"y_pred_class_dnn\"])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'DNN {activation_func} (AUC = {pr_auc:.2f})')\n",
    "\n",
    "# Define activation functions for ANN\n",
    "activation_functions_ann = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "# Plot precision-recall curves for ANN\n",
    "for activation_func, result in results_ann.items():\n",
    "    precision, recall, _ = precision_recall_curve(y_test, result[\"y_pred_class_ann\"])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'ANN {activation_func} (AUC = {pr_auc:.2f})', linestyle='dashed')\n",
    "\n",
    "plt.xlabel('Recall (True Positive Rate)', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curves for DNN and ANN', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model refinement for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:53:19.505054Z",
     "iopub.status.busy": "2024-03-20T12:53:19.504020Z",
     "iopub.status.idle": "2024-03-20T12:57:27.052481Z",
     "shell.execute_reply": "2024-03-20T12:57:27.051212Z",
     "shell.execute_reply.started": "2024-03-20T12:53:19.505017Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL 1 - Define the DNN architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(32,)))  # Input layer with ReLU activation\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dropout(0.2))  # Dropout regularization to reduce overfitting\n",
    "model.add(Dense(16, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_class))\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "y_pred_class_DNN2 = y_pred_class\n",
    "y_pred_class_DNN2 = y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T13:00:13.133921Z",
     "iopub.status.busy": "2024-03-20T13:00:13.133528Z",
     "iopub.status.idle": "2024-03-20T13:04:31.467201Z",
     "shell.execute_reply": "2024-03-20T13:04:31.466185Z",
     "shell.execute_reply.started": "2024-03-20T13:00:13.133894Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL 2 -  Define the DNN architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(32,)))  # Input layer with ReLU activation\n",
    "model.add(Dense(64, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dropout(0.3))  # Dropout regularization to reduce overfitting\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer with ReLU activation\n",
    "model.add(Dense(16, activation='relu'))  # Additional hidden layer with ReLU activation\n",
    "model.add(Dense(8, activation='relu'))  # Additional hidden layer with ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_class))\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "y_pred_class_DNN4 = y_pred_class\n",
    "y_pred_class_DNN4 = y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:50:40.977962Z",
     "iopub.status.busy": "2024-03-20T12:50:40.977515Z",
     "iopub.status.idle": "2024-03-20T12:50:41.652275Z",
     "shell.execute_reply": "2024-03-20T12:50:41.651267Z",
     "shell.execute_reply.started": "2024-03-20T12:50:40.977928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define confusion matrices\n",
    "conf_matrix_1 = np.array([[8639, 403], [26, 1001]]) # DNN Model 1 with downsampled 10 k dataset \n",
    "\n",
    "conf_matrix_2 = np.array([[8610, 432], [39, 988]]) # DNN Model 2 with downsampled 10 k dataset \n",
    "\n",
    "# Plot both confusion matrices side by side\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot confusion matrix 1\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(conf_matrix_1, annot=True, cmap=\"Blues\", fmt=\"d\", annot_kws={\"fontsize\": 14})\n",
    "plt.title(\"DNN Model 1 - downsampled dataset 10k\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "plt.ylabel(\"True Labels\", fontsize=14)\n",
    "\n",
    "# Plot confusion matrix 2\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(conf_matrix_2, annot=True, cmap=\"Blues\", fmt=\"d\", annot_kws={\"fontsize\": 14})\n",
    "plt.title(\"DNN Model 2 - downsampled dataset 10k\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "plt.ylabel(\"True Labels\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1542181,
     "sourceId": 2543148,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
